{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, to_date\n",
    "from pyspark.sql.functions import from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Checking Songs Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = os.path.join(output, 'songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/songs'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = spark.read.parquet(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['song_id', 'title', 'duration', 'year', 'artist_id']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------------------------------+---------+----+------------------+\n",
      "|song_id           |title                                        |duration |year|artist_id         |\n",
      "+------------------+---------------------------------------------+---------+----+------------------+\n",
      "|SOEKAZG12AB018837E|I'll Slap Your Face (Entertainment USA Theme)|129.85424|2001|ARSVTNL1187B992A91|\n",
      "|SOAFBCP12A8C13CC7D|King Of Scurf (2007 Digital Remaster)        |301.40036|1972|ARTC1LV1187B9A4858|\n",
      "|SORRNOC12AB017F52B|The Last Beat Of My Heart (b-side)           |337.81506|2004|ARSZ7L31187FB4E610|\n",
      "|SOQPWCR12A6D4FB2A3|A Poor Recipe For Civic Cohesion             |118.07302|2005|AR73AIO1187B9AD57B|\n",
      "|SOBRKGM12A8C139EF6|Welcome to the Pleasuredome                  |821.05424|1985|ARXQBR11187B98A2CC|\n",
      "+------------------+---------------------------------------------+---------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs.filter(songs['year']>0).show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking Artists Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = os.path.join(output, 'artists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/artists'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = spark.read.parquet(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist_id',\n",
       " 'artist_name',\n",
       " 'artist_location',\n",
       " 'artist_latitude',\n",
       " 'artist_longitude']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------+---------------------------------+---------------+----------------+\n",
      "|artist_id         |artist_name              |artist_location                  |artist_latitude|artist_longitude|\n",
      "+------------------+-------------------------+---------------------------------+---------------+----------------+\n",
      "|ARTC1LV1187B9A4858|The Bonzo Dog Band       |Goldsmith's College, Lewisham, Lo|51.4536        |-0.01802        |\n",
      "|ARA23XO1187B9AF18F|The Smithereens          |Carteret, New Jersey             |40.57885       |-74.21956       |\n",
      "|ARSVTNL1187B992A91|Jonathan King            |London, England                  |51.50632       |-0.12714        |\n",
      "|AR73AIO1187B9AD57B|Western Addiction        |San Francisco, CA                |37.77916       |-122.42005      |\n",
      "|ARXQBR11187B98A2CC|Frankie Goes To Hollywood|Liverpool, England               |null           |null            |\n",
      "+------------------+-------------------------+---------------------------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Checking Users Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = os.path.join(output, 'users' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = spark.read.parquet(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'frist_name', 'last_name', 'gender', 'level']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|frist_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     26|      Ryan|    Smith|     M| free|\n",
      "|     26|      Ryan|    Smith|     M| free|\n",
      "|     26|      Ryan|    Smith|     M| free|\n",
      "|     61|    Samuel| Gonzalez|     M| free|\n",
      "|     80|     Tegan|   Levine|     F| paid|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Checking Time Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = os.path.join(output, 'time_df' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = spark.read.parquet(time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp', 'hour', 'day', 'week', 'day_of_week', 'year', 'month']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----+---+----+-----------+----+-----+\n",
      "|timestamp              |hour|day|week|day_of_week|year|month|\n",
      "+-----------------------+----+---+----+-----------+----+-----+\n",
      "|2018-11-15 00:30:26.796|0   |15 |46  |Thursday   |2018|11   |\n",
      "|2018-11-15 00:41:21.796|0   |15 |46  |Thursday   |2018|11   |\n",
      "|2018-11-15 00:45:41.796|0   |15 |46  |Thursday   |2018|11   |\n",
      "|2018-11-15 03:44:09.796|3   |15 |46  |Thursday   |2018|11   |\n",
      "|2018-11-15 05:48:55.796|5   |15 |46  |Thursday   |2018|11   |\n",
      "+-----------------------+----+---+----+-----------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename columns https://stackoverflow.com/questions/34077353/how-to-change-dataframe-column-names-in-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|day_of_week|\n",
      "+-----------+\n",
      "|  Wednesday|\n",
      "|    Tuesday|\n",
      "|     Friday|\n",
      "|   Thursday|\n",
      "|   Saturday|\n",
      "|     Monday|\n",
      "|     Sunday|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_df.select(\"day_of_week\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Checking Songplays Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays = os.path.join(output, 'songplays' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/songplays'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songplays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays = spark.read.parquet(songplays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_Id',\n",
       " 'location',\n",
       " 'user_agent',\n",
       " 'session_id',\n",
       " 'artist_id',\n",
       " 'song_id',\n",
       " 'level',\n",
       " 'timestamp',\n",
       " 'year',\n",
       " 'month']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songplays.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+----------+---------+-------+-----+--------------------+----+-----+\n",
      "|user_Id|            location|          user_agent|session_id|artist_id|song_id|level|           timestamp|year|month|\n",
      "+-------+--------------------+--------------------+----------+---------+-------+-----+--------------------+----+-----+\n",
      "|     26|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|       583|     null|   null| free|2018-11-15 00:30:...|2018|   11|\n",
      "|     26|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|       583|     null|   null| free|2018-11-15 00:41:...|2018|   11|\n",
      "|     26|San Jose-Sunnyval...|\"Mozilla/5.0 (X11...|       583|     null|   null| free|2018-11-15 00:45:...|2018|   11|\n",
      "|     61|Houston-The Woodl...|\"Mozilla/5.0 (Mac...|       597|     null|   null| free|2018-11-15 03:44:...|2018|   11|\n",
      "|     80|Portland-South Po...|\"Mozilla/5.0 (Mac...|       602|     null|   null| paid|2018-11-15 05:48:...|2018|   11|\n",
      "+-------+--------------------+--------------------+----------+---------+-------+-----+--------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = os.path.join(\"data_2/log_data/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df =  spark.read.json(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = os.path.join(\"data_2/song_data/*.json\")\n",
    "song_df =  spark.read.json(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = song_df.alias('a').join(time_df).select('a.*',\n",
    "                                            time_df.timestamp, \n",
    "                                            time_df.hour)\n",
    "c.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "songplays_1 = log_df.join(song_df, \n",
    "                        (log_df.length == song_df.duration) & \n",
    "                        (log_df.artist == song_df.artist_name) & \n",
    "                        (log_df.song == song_df.title)).select(col('userId').alias('user_Id'),\n",
    "                                                               log_df.location,\n",
    "                                                               col('userAgent').alias('user_agent'),\n",
    "                                                               col('sessionId').alias('session_id'),\n",
    "                                                               song_df.artist_id,\n",
    "                                                               song_df.song_id,\n",
    "                                                               log_df.level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_Id: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays = songplays_1.alias('a').join(time_df).select('a.*',\n",
    "                                            time_df.timestamp, \n",
    "                                            time_df.hour)\n",
    "songplays.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_Id: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
